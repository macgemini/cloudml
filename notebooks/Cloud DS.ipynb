{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Machine Learning w chmurze - Cloud ML </h1>\n",
    "\n",
    "W tym notebooku pokażemy jak przenieść prosty model Tensorflow do GCP i uruchomić na nim predykcje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Predykcje na podstawie tekstu </h2>\n",
    "\n",
    "<b>Źródło danych</b>: Yelp Restaurant Reviews (https://www.yelp.com/dataset/challenge)\n",
    "\n",
    "Dataset zawiera między innymi informacje o restauracjach oraz opinie klientów\n",
    "\n",
    "Zadaniem jest przewidzenie czy restauracje przejdą inspekcje (amerykańskiego) sanepidu na podstawie opinii gości oraz dodatkowych informacji takich jak lokalizacja i rodzaje kuchni serwowanych w restauracji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Ustawienie zmiennych środowiskowych, import bibliotek </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 23:10:03.895156. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "BUCKET = 'dswbiznesie'\n",
    "PROJECT = 'dswbiznesie'\n",
    "REGION = 'europe-west1'\n",
    "REPO = '/content/datalab/dswbiznesie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%datalab project set -p $PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 23:09:02.825218. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import google.datalab.ml as ml\n",
    "import tensorflow as tf\n",
    "import apache_beam as beam\n",
    "import shutil\n",
    "import datetime\n",
    "from apache_beam.io.gcp.internal.clients import bigquery\n",
    "import pandas as pd\n",
    "import google.datalab.bigquery as bq\n",
    "print tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Dane źródłowe </h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset pobrany ze strony Yelp zawiera następujące pliki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 103941968  2017-11-06T00:52:39Z  gs://dswbiznesie/rawdata/hygiene/hygiene.dat\r\n",
      "    831242  2017-11-03T01:14:18Z  gs://dswbiznesie/rawdata/hygiene/hygiene.dat.additional\r\n",
      "    159046  2017-11-03T01:14:17Z  gs://dswbiznesie/rawdata/hygiene/hygiene.dat.labels\r\n",
      "TOTAL: 3 objects, 104932256 bytes (100.07 MiB)\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil -q ls -l gs://$BUCKET/rawdata/hygiene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>hygiene.dat</b>: każda linia zawiera połączone opinie klientów danej restauracji\n",
    "* <b>hygiene.dat.labels</b>: dla pierwszych 546 linii przypisana jest dodatkowe pole w którym 0 oznacza to że restauracja przeszła inspekcje, 1 to że restauracja <b>nie</b> przeszła inspekcji. Reszta wpisów posiada wpis \"[None]\" co oznacza że należą do zbioru testowego\n",
    "* <b>hygiene.dat.additional</b>: plik CSV gdzie w pierwszym polu znajduje się lista oferowanych rodzajów kuchnii, w drugim kod pocztowy restauracji który można uznać za przybliżenie lokalizacji restauracji. W trzecim polu znajduje się liczba opinii, w czwartym średnia ocena ( w skali 0-5, gdzie 5 oznacza ocene najlepszą)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Feature engineering używając Apache Beam i BigQuery</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dane źródłowe należy przetowrzyć i dostosować do postaci której będzie można łatwo użyć do uczenia i ewaluacji modelu. \n",
    "Najwygodniejszym choć nie najtańszym rozwiązaniem jest załadowanie danych do BigQuery.\n",
    "\n",
    "Odpowiednim narzędziem do tego zadania jest Apache Beam i jego implementacja - Google Dataflow.\n",
    "Job Dataflow uruchamiany jest w chmurze. Jego przebieg można śledzić w Konsoli GCP (https://console.cloud.google.com/dataflow).\n",
    "Uruchomienie joba trwa powyżej minuty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_record(rest_tuple):\n",
    "    #print(rest_tuple)\n",
    "    identity = rest_tuple[0]\n",
    "    reviews = rest_tuple[1]['reviews_kv'][0]\n",
    "    inspection_result = int(rest_tuple[1]['labels_kv'][0]) if rest_tuple[1]['labels_kv'][0] != \"[None]\" else None\n",
    "    categories_temp = rest_tuple[1]['attributes_kv'][0].split(\"\\\"\")\n",
    "    categories = \",\".join([ x.replace('\\'', '').replace('[','').replace(']','').strip() for x in categories_temp[1].split(',')])\n",
    "    #categories = categories_temp[1].replace('\\'', '').replace('[','').replace(']','')\n",
    "    attributes_temp = categories_temp[2].split(\",\")\n",
    "    zip_code = attributes_temp[1]\n",
    "    review_count = int(attributes_temp[2])\n",
    "    avg_rating = float(attributes_temp[3])\n",
    "    \n",
    "    return { \n",
    "        'identity': identity, \n",
    "        'reviews': reviews,\n",
    "        'inspection_result': inspection_result,\n",
    "        'categories': categories,\n",
    "        'zip_code': zip_code,\n",
    "        'review_count': review_count,\n",
    "        'avg_rating': avg_rating\n",
    "    }\n",
    "\n",
    "def preprocess(RUNNER,BUCKET,BIGQUERY_TABLE):\n",
    "    job_name = 'hygiene-ftng' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    print 'Launching Dataflow job {} ... hang on'.format(job_name)\n",
    "    OUTPUT_DIR = 'gs://{0}/data/hygiene/'.format(BUCKET)\n",
    "    options = {\n",
    "        'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "        'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "        'job_name': 'hygiene-ftng' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S'),\n",
    "        'project': PROJECT,\n",
    "        'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "        'no_save_main_session': True\n",
    "    }\n",
    "    opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "    p = beam.Pipeline(RUNNER, options=opts)\n",
    "    \n",
    "    # Adding table definition\n",
    "    table_schema = bigquery.TableSchema()\n",
    "    \n",
    "    # Fields definition\n",
    "    identity_schema = bigquery.TableFieldSchema()\n",
    "    identity_schema.name = 'identity'\n",
    "    identity_schema.type = 'integer'\n",
    "    identity_schema.mode = 'required'\n",
    "    table_schema.fields.append(identity_schema)\n",
    "    \n",
    "    \n",
    "    reviews_schema = bigquery.TableFieldSchema()\n",
    "    reviews_schema.name = 'reviews'\n",
    "    reviews_schema.type = 'string'\n",
    "    reviews_schema.mode = 'required'\n",
    "    table_schema.fields.append(reviews_schema)\n",
    "\n",
    "    inspection_result_schema = bigquery.TableFieldSchema()\n",
    "    inspection_result_schema.name = 'inspection_result'\n",
    "    inspection_result_schema.type = 'integer'\n",
    "    inspection_result_schema.mode = 'nullable'\n",
    "    table_schema.fields.append(inspection_result_schema)\n",
    "    \n",
    "    categories_schema = bigquery.TableFieldSchema()\n",
    "    categories_schema.name = 'categories'\n",
    "    categories_schema.type = 'string'\n",
    "    categories_schema.mode = 'required'\n",
    "    table_schema.fields.append(categories_schema)\n",
    "    \n",
    "    zip_code_schema = bigquery.TableFieldSchema()\n",
    "    zip_code_schema.name = 'zip_code'\n",
    "    zip_code_schema.type = 'string'\n",
    "    zip_code_schema.mode = 'required'\n",
    "    table_schema.fields.append(zip_code_schema)\n",
    "    \n",
    "    review_count_schema = bigquery.TableFieldSchema()\n",
    "    review_count_schema.name = 'review_count'\n",
    "    review_count_schema.type = 'integer'\n",
    "    review_count_schema.mode = 'required'\n",
    "    table_schema.fields.append(review_count_schema)\n",
    "    \n",
    "    avg_rating_schema = bigquery.TableFieldSchema()\n",
    "    avg_rating_schema.name = 'avg_rating'\n",
    "    avg_rating_schema.type = 'float'\n",
    "    avg_rating_schema.mode = 'required'\n",
    "    table_schema.fields.append(avg_rating_schema)\n",
    "    \n",
    "    #processing logic\n",
    "    reviews = p | 'readreviews' >> beam.io.ReadFromText('gs://{0}/rawdata/hygiene/hygiene.dat'.format(BUCKET))\n",
    "    labels = p | 'readlabels' >> beam.io.ReadFromText('gs://{0}/rawdata/hygiene/hygiene.dat.labels'.format(BUCKET))\n",
    "    attributes = p | 'readattributes' >> beam.io.ReadFromText('gs://{0}/rawdata/hygiene/hygiene.dat.additional'.format(BUCKET))\n",
    "    \n",
    "    reviews_kv = reviews | 'mapreviews to kv' >> beam.Map(lambda x: (x.split(\",\")[0], \",\".join(x.split(\",\")[1:]).replace(\"|\",\"\")))\n",
    "    labels_kv = labels | 'maplabels to kv' >> beam.Map(lambda x: (x.split(\",\")[0], x.split(\",\")[1]))\n",
    "    attributes_kv = attributes | 'mapattributes to kv' >> beam.Map(lambda x: (x.split(\",\")[0], x))\n",
    "    \n",
    "    restaurants = (\n",
    "        {'reviews_kv': reviews_kv, 'labels_kv': labels_kv, 'attributes_kv': attributes_kv}\n",
    "        | 'CoGroupByRestaurantKey' >> beam.CoGroupByKey())\n",
    "    \n",
    "    records = restaurants | 'CreateRecords' >> beam.Map(create_record)\n",
    "    \n",
    "    records | 'write' >> beam.io.Write(\n",
    "        beam.io.BigQuerySink(\n",
    "            BIGQUERY_TABLE,\n",
    "            schema=table_schema,\n",
    "            create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "            write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE))\n",
    "    p.run().wait_until_finish()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Uruchomienie etl </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Dataflow job hygiene-ftng-171109-214638 ... hang on\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "bigquery_dataset = PROJECT+\":\"+PROJECT+\".hygiene\"\n",
    "preprocess('DirectRunner',BUCKET, bigquery_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Przygotowanie danych do trenowania modelu </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Pobranie danych do DataFrame (pandas) </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 22:52:42.386217. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "query=\"\"\"\n",
    "SELECT\n",
    "  #identity,\n",
    "  reviews,\n",
    "  inspection_result #,\n",
    "  #categories,\n",
    "  #zip_code,\n",
    "  #review_count,\n",
    "  #avg_rating\n",
    "FROM\n",
    "  `dswbiznesie.hygiene`\n",
    "WHERE\n",
    "  inspection_result IS NOT NULL\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 22:52:46.583146. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#df = bq.Query(query).execute().result().to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Podzial danych na zestaw treningowy i ewaluacyjny </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>inspection_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was expecting a lot more given all the grea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I usually can be found here every now &amp;amp; t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Om nom nom. Not the best I've ever had, but i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sweet tea, sweet potato fries, fried green to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I remember coming here as a wide-eyed 8 year ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  inspection_result\n",
       "0   I was expecting a lot more given all the grea...                  0\n",
       "1   I usually can be found here every now &amp; t...                  0\n",
       "2   Om nom nom. Not the best I've ever had, but i...                  0\n",
       "3   Sweet tea, sweet potato fries, fried green to...                  0\n",
       "4   I remember coming here as a wide-eyed 8 year ...                  0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 22:52:54.484154. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "traindf = bq.Query(query + \" AND MOD(ABS(FARM_FINGERPRINT(reviews)),4) > 0\").execute().result().to_dataframe()\n",
    "evaldf  = bq.Query(query + \" AND MOD(ABS(FARM_FINGERPRINT(reviews)),4) = 0\").execute().result().to_dataframe()\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    205\n",
       "1    203\n",
       "Name: inspection_result, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 22:53:10.521939. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "traindf['inspection_result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    70\n",
       "0    68\n",
       "Name: inspection_result, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 22:53:12.874120. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "evaldf['inspection_result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 22:53:28.888152. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "traindf.to_csv('train.csv', header=False, index=False, encoding='utf-8', sep='|')\n",
    "evaldf.to_csv('eval.csv', header=False, index=False, encoding='utf-8', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I was expecting a lot more given all the great reviews!I ordered the dumplings, Kung Pao Chicken and the chow mein with homemade noodles. The dumplings were pretty good but I wouldn't say they were really anything special. I didn't even eat more than a few bites of the Kung Pao Chicken. The chicken was cheap and gross and I couldn't even choke it down. The noodles were good enough, but I agree with the reviewer who thought they were a bit dry. I followed that reviewer's advice and poured my leftover dumpling sauce all over them. Once again, the chicken in the noodles was inedible and I ate around it. I was expecting to have leftovers afterwards, but I have no desire to take up space in my fridge with not very good Chinese food I won't even want to eat later. I won't be ordering again! This was a last minute desperation kind of visit. &#160;We were driving around the area looking for something to eat and nothing sounded good. &#160;Chinese food is always sort of a safe bet for us. &#160;We can usually find something that both of us will eat. &#160;We came in pretty late and thought that they wouldn't want us there but the woman who ran the spot was more than happy to have our business. &#160;She was very attentive and brought our drinks and took our order almost immediately. &#160;She then brought us out some pot stickers which were great. &#160;A very nice surprise.My chicken &amp; noodle dish was very good. &#160;It was nice and hot and not drowning in sauce. &#160;Very good and, considering the price, I thought it was a bargain. &#160;I'd love to go back here but I rarely spend time in this neighborhood. &#160;If I do end up over there, I will be there. Mandarin Chef was something I wanted to try after reading all the positive reviews on here. &#160;First off the lady working there was very kind and insisted we stay and eat instead of getting our food to-go. &#160;Also I was very happy with how clean the restaurant was inside. &#160;We ordered the chicken chow mein, sweet and sour chicken, and general tsos chicken. &#160;The food came out quickly, about ten minutes. &#160;The chow mein was mediocre...I thought the noodles were homeade? &#160;It seemed like a basic chow mein you'd get at safeway honestly, maybe I ordered the wrong one? &#160;Anyway the general tsos chicken was tasty, I ordered it spicy (level 4) the sauce was so good so I &#160;added it to the bland tasting chow mein. &#160;The sweet and sour chicken also had good flavor. &#160; Overall it wasn't the best chinese I've ever had but I would go back again.|0\r\n",
      "\" I usually can be found here every now &amp; then if I'm in the Georgetown area.+Piping hot chinese food.+Fast &amp; Friendly customer service.+Plenty of seating.+Portions are huge.-Location.-Environment feels kind of blah -_--The food is not healthy at all.I'd still check them out. Red House is not everyone's cup of tea. &#160;It's blue collar, stick to your ribs, super-sized portions of \"\"Americanized\"\" Chinese food. &#160;That being said, it is a guilty pleasure to eat there occasionally. &#160;The best thing there are the egg rolls. &#160;They are huge, greasy and filled with pork and vegetables. &#160;The people who work there are always friendly and like I said the portions are well worth the reasonable price. &#160;Just know going in that this is not some fancy place with exotic flavors, but I always stop in when I'm driving through Georgetown.\"|0\r\n",
      "\" Om nom nom. Not the best I've ever had, but it sure was easy to eat! Our waitress was sort of a bitch, it seemed like she was having a bad day. We went around 7pm on a weeknight and it was REALLY loud. Been here a couple of times. &#160;The pizza is fine, probably better than most local places. &#160;The beer selection is nice. &#160;The location and decor is great.However, this place has a couple of problems, probably due to poor management. &#160;First off, as others have pointed out, the servers can be kind of jerky-- like \"\"I hate my job\"\" jerky.Second, forget the booths near the door in the cooler weather. &#160;They are freezing cold. &#160;This is based on a number of visits. &#160;A better door-closer mechanism would solve most of this.Third, the place is insufferably loud. &#160;On a weekday early evening, we were sitting in a booth and could barely hold a conversation. &#160;The noise wasn't from audio system or the smallish crowd of customers. &#160;It was from the kitchen. &#160;The whole meal I kept thinking \"\"Why isn't someone doing something about that guy slamming pans and dishes around all night?\"\" &#160;Then I guessed he probably had headphones on, and as we were leaving, I peeked thru the window, and sure enough, the guy was wearing headphones, totally oblivious to the ear-bleeding racket he was causing to those on the other side of the wall.Really good food, nice space, but the staff needs some better management. I'd heard good things about Belltown Pizza and desperately wanted it to be a 5, but alas, it was pretty ordinary. Nothing wrong with it, but I tried a few different combinations and all of them were just fine. I would dine here again, but wouldn't make it a top recommended pizza place for my friends. I came here on a Saturday night when I was hungry enough to choose the first place that would seat us. After trying a couple restaurants in the area, we chose this place because they were able to seat us immediately. The fact that they weren't overly crowded should not be a sign that the food wasn't good! I really enjoyed the pizza here. We ordered the \"\"House\"\" pizza which is a fresh garlic, roma tomato and feta cheese pizza. The feta cheese was really nice and not overpowering. The pizza had a thin crust which wasn't so thin that the toppings made the crust soggy. That's no fun. Overall, a very satisfying pizza. I definitely want to come back and try their other specialty pizzas which sounded delicious. This joing is fine for grabbing a slice and a couple beers, but just know that the pizza is pretty weak. Also, service, the check, and even drinks take alot longer than they should. I used to kick it in Belltown quite a bit after I turned 21, so I've stopped in here many times. I've managed to try most of what they offer by slice, and I have to say it was never really that good. They usually don't have nearly enough variety of pizzas to choose from, so you end up waiting for them to make ones with different toppings or just churn out new ones so you get a hot, fresh slice.Thinking back, I don't really know why we went back--I guess just because it happened to be convenient and cheap. I've tried pizza at multiple places in Seattle, and Belltown is one of the best places to go grab a slice of pie! *Top Pizza Restaurants* in Seattle (not listed in any order): 1.) Belltown Pizza 2.) La Vita E Bella 3.) Serious Pie 4.) Via Tribunali I recommend the Carol's Pie! They don't deliver however you can call in advance to place an order. Their prices are what you would expect for pizza, about the same as a Dominos, but 100 times better! They have some booths to sit at, as well as a bunch of tables and a bar. The restaurant is artsy, they even have an old fashioned bike hanging above the bar. There are a few flat screen TVs which is cool if you are someone who likes to watch the game or feels like hanging out there late at night. I'm pretty sure they open later in the day, but the awesome thing is, they are open until 1:30 or 2:00am! After a certain time the restaurant closes, and in the late evenings, you need to be 21+ to go inside because it turns into a bar and only serves pizza by the slice. In the summer it's fun because you can sit outside as well. They do serve salads- for those of you who are watching your figure and dating someone who loves pizza, so it's a good comprimise. Definitely try it out! I can guarantee it will be on your list of top pizza places in Seattle! It's better than Zeeks and Pagliaccis! I just moved to Seattle from NYC, and was very happy. Great Specials for pizza lovers. $20 Tuesdays includes a large pizza and a bucket of 4 beers(Sessions). $25 Wednesdays offers a large pizza with a bottle of wine. It is the best pizza I have had in Seattle so far. &#160;Please yelp me a better one if you know it.Great NYC style pizza, tasty crust, outdoor seating in a funky atmosphere. &#160;Always great table and bar service and the price is right. &#160;This rating would have been four stars but they serve Fernet Branca . . so . . . Traditional New York style pizza. &#160;DELICIOUS! &#160;However, their friendly service and good mix of music is what keeps me going back. &#160;Its my fail safe. &#160;If you can't decide on anywhere to go, go here! &#160;Can't go wrong!By the way, they have a great pizza and beer special on Tuesday night. &#160;Go check it out for your self. I was once denied entry to Belltown Pizza for asking the door guy if I could pet his beard. But that's neither here nor there.This review is for one thing on the meny: CHEESY BREAD! One could call it \"\"clumsy\"\" or \"\"basic\"\" or \"\"low-brow\"\" - however, I call it DELICIOUS. Is there crack in that red sauce, or is it just 4 pounds of garlic? I don't know. But when I've had a couple adult beverages, this stuff is wonderous. Pizza was average -- got the bbq chicken and josh's favorite -- Make sure you get the cheese/garlic bread, it has got to be the best in Seattle! i got a slice of the pepp and the hawaiian last night. &#160;missed happy hr, so i got a guinness. &#160;the bartender poured it right! &#160;he poured it partially full, then finished it off a few min later after it sat. &#160;when i got it, my buddy told me to check out the design on top and i was pleasantly shocked to find he somehow drew the i-love-you hand gesture into the head of the beer!! &#160;very cool... I just moved into the neighborhood (2 blocks away), and I have been looking to find my signature pizza joint. This was my first visit to Belltown pizza, and I have heard some good things, but I have to say I was a bit disappointed. The pizza was good, but not the same caliber of Pagliacci's or many other pizza joints in Seattle. I am normally not hard to please if people are friendly, etc. I noticed a few other comments about the people working there having bad attitudes, etc, and that was honestly my first impression of the place. The man behind the bar that greeted me did not smile, and barely even acknowledged me. &#160;One girl was quite friendly, but the general atmosphere was kind of dark and unfriendly. Unfortunately, this will most likely be the first and last visit to Belltown Pizza. The next time somebody tells me Belltown pizza is good or asks me about it, I will most likely give them the answer above. One of the many reason I am sad I left Seattle is that I can't walk down the street and get a fine slice of pizza from Belltown Pizza. I don't know what the other people are thinking when they say the pizza is just ok, this pizza is the best pizza I've ever had. If you are a thin crust/NY style pizza lover, you will absolutely love this place.During the winter months there is trivia night on Monday, and that is very fun as well. Happy hour prices are 2 bucks a slice and cheap beer as well. I know that when I make my return trip/vacation to Seattle, Belltown Pizza will be one of the first places I go. Seriously good pizza and they are open late.After a raucous evening at Cyclops, we ran across the street for some pizza, not expecting it to be THAT great. We were pleasantly surprised - delicious!Also, they don't mind if you and your friends sing Neil Diamond late into the night. Belltown Pizza has the best Tuesday night special. &#160;A bucket of 4 Session beers, and a 2 topping pizza for $20! Always a great Tuesday night out, and we don't usually have to wait for a table. Staff is friendly and service is pretty fast, as long as they're not slammed. Only giving it 4 or 4.5 stars because although its really good NY style pizza, its not the best I've ever had. I have gone here a few times for their happy hour from 4-6. For $5 I got a slice of pizza and a beer, and I was quite satisfied, I returned again later that week with a friend and we each got a slice of pizza he had one beer and 2 mixed drinks, and I had 3 beers and our total was less than $20! Good drinks, decent pizza, excellent prices. I had a plain pizza of pizza here, and thought it was okay. The staff guy behind the counter was okay, seemed like he had been working long hours. &#160;If you're by there, try it out.\"|0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 22:53:32.159166. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "!head -3 train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    138 eval.csv\r\n",
      "    408 train.csv\r\n",
      "    408 vocab.csv\r\n",
      "    954 total\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 22:53:44.317176. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "!wc -l *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://eval.csv [Content-Type=text/csv]...\n",
      "Copying file://train.csv [Content-Type=text/csv]...\n",
      "Copying file://vocab.csv [Content-Type=text/csv]...\n",
      "- [3 files][  7.6 MiB/  7.6 MiB]                                                \n",
      "Operation completed over 3 objects/7.6 MiB.                                      \n",
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 22:53:47.182163. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil cp *.csv gs://${BUCKET}/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0  2017-11-03T00:08:16Z  gs://dswbiznesie/data/\r\n",
      "   1236330  2017-11-09T22:53:48Z  gs://dswbiznesie/data/eval.csv\r\n",
      "   3334214  2017-11-09T22:53:48Z  gs://dswbiznesie/data/train.csv\r\n",
      "   3354636  2017-11-09T22:53:49Z  gs://dswbiznesie/data/vocab.csv\r\n",
      "     25091  2017-11-09T22:27:47Z  gs://dswbiznesie/data/vocab_words\r\n",
      "TOTAL: 5 objects, 7950271 bytes (7.58 MiB)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 22:53:54.781813. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "!gsutil -q ls -l gs://$BUCKET/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Model Tensorflow </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Właściwy model tensorflow znajduje się w pliku <b>model.py</b> a definicja joba Cloud ML w pliku <b>task.py</b>\n",
    "Kod poniżej ma za zadanie zilutrować działanie kodu tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n",
      "118 words into vocab.tsv\n",
      "This might be the best \"taco\" truck on the planet. Hidden between a smoke shop and The Home Depot, this semi permanent, stylish and clean cafe on wheels. --> [ 42  12  41 118  33 119  51  47 118 119  96  39 112  54   1  87 111  56\n",
      " 119  81  19 119  23  87 117  99  47 119]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/ndimage/measurements.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _ni_label\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/ndimage/measurements.py:36: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  from . import _ni_label\n",
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 22:54:00.688164. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import lookup\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "print tf.__version__\n",
    "MAX_DOCUMENT_LENGTH = 100000  \n",
    "PADWORD = 'ZYXW'\n",
    "\n",
    "# vocabulary\n",
    "lines = ['This might be the best \"taco\" truck on the planet. Hidden between a smoke shop and The Home Depot, this semi permanent, stylish and clean cafe on wheels.', \n",
    "         'Im always looking for a good place to sing karaoke. This is one of them. Drinks are cheap. Food is delicious. And its laid back and fun. I shall return!', \n",
    "         'Crazy Man just Crazy there are like 3 different places called Saigon Deli at this intersection but this one is on Jackson just west of twelfthand with $2 pork Banh Mi you cant go wrong, I am going to Indiana for work so I went in and got 6 Pork', \n",
    "         'Ive eaten here a few times in the past and thought it was decent. I went last night, however, and our meal was really subpar so the place seems to have gone down hill.We had chow fun noodles and the hollow vegetables with chili sauce']\n",
    "\n",
    "# create vocabulary\n",
    "vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH)\n",
    "vocab_processor.fit(lines)\n",
    "with gfile.Open('vocab.tsv', 'wb') as f:\n",
    "    f.write(\"{}\\n\".format(PADWORD))\n",
    "    for word, index in vocab_processor.vocabulary_._mapping.iteritems():\n",
    "      f.write(\"{}\\n\".format(word))\n",
    "N_WORDS = len(vocab_processor.vocabulary_)\n",
    "print '{} words into vocab.tsv'.format(N_WORDS)\n",
    "\n",
    "# can use the vocabulary to convert words to numbers\n",
    "table = lookup.index_table_from_file(\n",
    "  vocabulary_file='vocab.tsv', num_oov_buckets=1, vocab_size=None, default_value=-1)\n",
    "numbers = table.lookup(tf.constant(lines[0].split()))\n",
    "with tf.Session() as sess:\n",
    "  tf.tables_initializer().run()\n",
    "  print \"{} --> {}\".format(lines[0], numbers.eval())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZYXW\r\n",
      "shop\r\n",
      "just\r\n",
      "cheap\r\n",
      "go\r\n",
      "Indiana\r\n",
      "its\r\n",
      "We\r\n",
      "seems\r\n",
      "laid\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 22:54:06.395151. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "!head vocab.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews= [ 'This might be the best \"taco\" truck on the planet. Hidden between a smoke shop and The Home Depot, this semi permanent, stylish and clean cafe on wheels.'\n",
      " 'Im always looking for a good place to sing karaoke. This is one of them. Drinks are cheap. Food is delicious. And its laid back and fun. I shall return!'\n",
      " 'Crazy Man just Crazy there are like 3 different places called Saigon Deli at this intersection but this one is on Jackson just west of twelfthand with $2 pork Banh Mi you cant go wrong, I am going to Indiana for work so I went in and got 6 Pork'\n",
      " 'Ive eaten here a few times in the past and thought it was decent. I went last night, however, and our meal was really subpar so the place seems to have gone down hill.We had chow fun noodles and the hollow vegetables with chili sauce'] (4,)\n",
      "words= SparseTensorValue(indices=array([[ 0,  0],\n",
      "       [ 0,  1],\n",
      "       [ 0,  2],\n",
      "       [ 0,  3],\n",
      "       [ 0,  4],\n",
      "       [ 0,  5],\n",
      "       [ 0,  6],\n",
      "       [ 0,  7],\n",
      "       [ 0,  8],\n",
      "       [ 0,  9],\n",
      "       [ 0, 10],\n",
      "       [ 0, 11],\n",
      "       [ 0, 12],\n",
      "       [ 0, 13],\n",
      "       [ 0, 14],\n",
      "       [ 0, 15],\n",
      "       [ 0, 16],\n",
      "       [ 0, 17],\n",
      "       [ 0, 18],\n",
      "       [ 0, 19],\n",
      "       [ 0, 20],\n",
      "       [ 0, 21],\n",
      "       [ 0, 22],\n",
      "       [ 0, 23],\n",
      "       [ 0, 24],\n",
      "       [ 0, 25],\n",
      "       [ 0, 26],\n",
      "       [ 0, 27],\n",
      "       [ 1,  0],\n",
      "       [ 1,  1],\n",
      "       [ 1,  2],\n",
      "       [ 1,  3],\n",
      "       [ 1,  4],\n",
      "       [ 1,  5],\n",
      "       [ 1,  6],\n",
      "       [ 1,  7],\n",
      "       [ 1,  8],\n",
      "       [ 1,  9],\n",
      "       [ 1, 10],\n",
      "       [ 1, 11],\n",
      "       [ 1, 12],\n",
      "       [ 1, 13],\n",
      "       [ 1, 14],\n",
      "       [ 1, 15],\n",
      "       [ 1, 16],\n",
      "       [ 1, 17],\n",
      "       [ 1, 18],\n",
      "       [ 1, 19],\n",
      "       [ 1, 20],\n",
      "       [ 1, 21],\n",
      "       [ 1, 22],\n",
      "       [ 1, 23],\n",
      "       [ 1, 24],\n",
      "       [ 1, 25],\n",
      "       [ 1, 26],\n",
      "       [ 1, 27],\n",
      "       [ 1, 28],\n",
      "       [ 1, 29],\n",
      "       [ 2,  0],\n",
      "       [ 2,  1],\n",
      "       [ 2,  2],\n",
      "       [ 2,  3],\n",
      "       [ 2,  4],\n",
      "       [ 2,  5],\n",
      "       [ 2,  6],\n",
      "       [ 2,  7],\n",
      "       [ 2,  8],\n",
      "       [ 2,  9],\n",
      "       [ 2, 10],\n",
      "       [ 2, 11],\n",
      "       [ 2, 12],\n",
      "       [ 2, 13],\n",
      "       [ 2, 14],\n",
      "       [ 2, 15],\n",
      "       [ 2, 16],\n",
      "       [ 2, 17],\n",
      "       [ 2, 18],\n",
      "       [ 2, 19],\n",
      "       [ 2, 20],\n",
      "       [ 2, 21],\n",
      "       [ 2, 22],\n",
      "       [ 2, 23],\n",
      "       [ 2, 24],\n",
      "       [ 2, 25],\n",
      "       [ 2, 26],\n",
      "       [ 2, 27],\n",
      "       [ 2, 28],\n",
      "       [ 2, 29],\n",
      "       [ 2, 30],\n",
      "       [ 2, 31],\n",
      "       [ 2, 32],\n",
      "       [ 2, 33],\n",
      "       [ 2, 34],\n",
      "       [ 2, 35],\n",
      "       [ 2, 36],\n",
      "       [ 2, 37],\n",
      "       [ 2, 38],\n",
      "       [ 2, 39],\n",
      "       [ 2, 40],\n",
      "       [ 2, 41],\n",
      "       [ 2, 42],\n",
      "       [ 2, 43],\n",
      "       [ 2, 44],\n",
      "       [ 2, 45],\n",
      "       [ 2, 46],\n",
      "       [ 2, 47],\n",
      "       [ 2, 48],\n",
      "       [ 2, 49],\n",
      "       [ 3,  0],\n",
      "       [ 3,  1],\n",
      "       [ 3,  2],\n",
      "       [ 3,  3],\n",
      "       [ 3,  4],\n",
      "       [ 3,  5],\n",
      "       [ 3,  6],\n",
      "       [ 3,  7],\n",
      "       [ 3,  8],\n",
      "       [ 3,  9],\n",
      "       [ 3, 10],\n",
      "       [ 3, 11],\n",
      "       [ 3, 12],\n",
      "       [ 3, 13],\n",
      "       [ 3, 14],\n",
      "       [ 3, 15],\n",
      "       [ 3, 16],\n",
      "       [ 3, 17],\n",
      "       [ 3, 18],\n",
      "       [ 3, 19],\n",
      "       [ 3, 20],\n",
      "       [ 3, 21],\n",
      "       [ 3, 22],\n",
      "       [ 3, 23],\n",
      "       [ 3, 24],\n",
      "       [ 3, 25],\n",
      "       [ 3, 26],\n",
      "       [ 3, 27],\n",
      "       [ 3, 28],\n",
      "       [ 3, 29],\n",
      "       [ 3, 30],\n",
      "       [ 3, 31],\n",
      "       [ 3, 32],\n",
      "       [ 3, 33],\n",
      "       [ 3, 34],\n",
      "       [ 3, 35],\n",
      "       [ 3, 36],\n",
      "       [ 3, 37],\n",
      "       [ 3, 38],\n",
      "       [ 3, 39],\n",
      "       [ 3, 40],\n",
      "       [ 3, 41],\n",
      "       [ 3, 42],\n",
      "       [ 3, 43],\n",
      "       [ 3, 44]]), values=array(['This', 'might', 'be', 'the', 'best', '\"taco\"', 'truck', 'on',\n",
      "       'the', 'planet.', 'Hidden', 'between', 'a', 'smoke', 'shop', 'and',\n",
      "       'The', 'Home', 'Depot,', 'this', 'semi', 'permanent,', 'stylish',\n",
      "       'and', 'clean', 'cafe', 'on', 'wheels.', 'Im', 'always', 'looking',\n",
      "       'for', 'a', 'good', 'place', 'to', 'sing', 'karaoke.', 'This', 'is',\n",
      "       'one', 'of', 'them.', 'Drinks', 'are', 'cheap.', 'Food', 'is',\n",
      "       'delicious.', 'And', 'its', 'laid', 'back', 'and', 'fun.', 'I',\n",
      "       'shall', 'return!', 'Crazy', 'Man', 'just', 'Crazy', 'there', 'are',\n",
      "       'like', '3', 'different', 'places', 'called', 'Saigon', 'Deli',\n",
      "       'at', 'this', 'intersection', 'but', 'this', 'one', 'is', 'on',\n",
      "       'Jackson', 'just', 'west', 'of', 'twelfthand', 'with', '$2', 'pork',\n",
      "       'Banh', 'Mi', 'you', 'cant', 'go', 'wrong,', 'I', 'am', 'going',\n",
      "       'to', 'Indiana', 'for', 'work', 'so', 'I', 'went', 'in', 'and',\n",
      "       'got', '6', 'Pork', 'Ive', 'eaten', 'here', 'a', 'few', 'times',\n",
      "       'in', 'the', 'past', 'and', 'thought', 'it', 'was', 'decent.', 'I',\n",
      "       'went', 'last', 'night,', 'however,', 'and', 'our', 'meal', 'was',\n",
      "       'really', 'subpar', 'so', 'the', 'place', 'seems', 'to', 'have',\n",
      "       'gone', 'down', 'hill.We', 'had', 'chow', 'fun', 'noodles', 'and',\n",
      "       'the', 'hollow', 'vegetables', 'with', 'chili', 'sauce'], dtype=object), dense_shape=array([ 4, 50]))\n",
      "dense= [['This' 'might' 'be' 'the' 'best' '\"taco\"' 'truck' 'on' 'the' 'planet.'\n",
      "  'Hidden' 'between' 'a' 'smoke' 'shop' 'and' 'The' 'Home' 'Depot,' 'this'\n",
      "  'semi' 'permanent,' 'stylish' 'and' 'clean' 'cafe' 'on' 'wheels.' 'ZYXW'\n",
      "  'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW'\n",
      "  'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW'\n",
      "  'ZYXW']\n",
      " ['Im' 'always' 'looking' 'for' 'a' 'good' 'place' 'to' 'sing' 'karaoke.'\n",
      "  'This' 'is' 'one' 'of' 'them.' 'Drinks' 'are' 'cheap.' 'Food' 'is'\n",
      "  'delicious.' 'And' 'its' 'laid' 'back' 'and' 'fun.' 'I' 'shall' 'return!'\n",
      "  'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW'\n",
      "  'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW']\n",
      " ['Crazy' 'Man' 'just' 'Crazy' 'there' 'are' 'like' '3' 'different'\n",
      "  'places' 'called' 'Saigon' 'Deli' 'at' 'this' 'intersection' 'but' 'this'\n",
      "  'one' 'is' 'on' 'Jackson' 'just' 'west' 'of' 'twelfthand' 'with' '$2'\n",
      "  'pork' 'Banh' 'Mi' 'you' 'cant' 'go' 'wrong,' 'I' 'am' 'going' 'to'\n",
      "  'Indiana' 'for' 'work' 'so' 'I' 'went' 'in' 'and' 'got' '6' 'Pork']\n",
      " ['Ive' 'eaten' 'here' 'a' 'few' 'times' 'in' 'the' 'past' 'and' 'thought'\n",
      "  'it' 'was' 'decent.' 'I' 'went' 'last' 'night,' 'however,' 'and' 'our'\n",
      "  'meal' 'was' 'really' 'subpar' 'so' 'the' 'place' 'seems' 'to' 'have'\n",
      "  'gone' 'down' 'hill.We' 'had' 'chow' 'fun' 'noodles' 'and' 'the' 'hollow'\n",
      "  'vegetables' 'with' 'chili' 'sauce' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW' 'ZYXW']] (?, ?)\n",
      "numbers= [[ 42  12  41 118  33 119  51  47 118 119  96  39 112  54   1  87 111  56\n",
      "  119  81  19 119  23  87 117  99  47 119   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [116  20  36  35 112  14  53  10  46 119  42  89  62  50 119  58  30 119\n",
      "  100  89 119  77   6   9  28  87 119 106 105 119   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 79 104   2  79  68  30  18  37  98  80  86  88 115  93  81  17  73  81\n",
      "   62  89  47  27   2  66  50  49  75 119  26 103  43 102  92   4 119 106\n",
      "   90  70  10   5  35  83 101 106  24  95  87  40  71 113]\n",
      " [ 78 109  45 112  69  52  95 118  29  87 114  91  72 119 106  24  48 119\n",
      "  119  87  31  25  72  34  59 101 118  53   8  10  94  60  63 119  61 107\n",
      "   85  32  87 118  21  67  75  74  82   0   0   0   0   0]] (?, ?)\n",
      "padding= [[     0      0]\n",
      " [     0 100000]] (2, 2)\n",
      "padded= [[ 42  12  41 ...,   0   0   0]\n",
      " [116  20  36 ...,   0   0   0]\n",
      " [ 79 104   2 ...,   0   0   0]\n",
      " [ 78 109  45 ...,   0   0   0]] (?, ?)\n",
      "sliced= [[ 42  12  41 ...,   0   0   0]\n",
      " [116  20  36 ...,   0   0   0]\n",
      " [ 79 104   2 ...,   0   0   0]\n",
      " [ 78 109  45 ...,   0   0   0]] (?, 100000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 22:54:08.087158. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "# string operations\n",
    "reviews = tf.constant(lines)\n",
    "words = tf.string_split(reviews)\n",
    "densewords = tf.sparse_tensor_to_dense(words, default_value=PADWORD)\n",
    "numbers = table.lookup(densewords)\n",
    "\n",
    "# now pad out with zeros and then slice to constant length\n",
    "padding = tf.constant([[0,0],[0,MAX_DOCUMENT_LENGTH]])\n",
    "padded = tf.pad(numbers, padding)\n",
    "sliced = tf.slice(padded, [0,0], [-1, MAX_DOCUMENT_LENGTH])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  tf.tables_initializer().run()\n",
    "  print \"reviews=\", reviews.eval(), reviews.shape\n",
    "  print \"words=\", words.eval()\n",
    "  print \"dense=\", densewords.eval(), densewords.shape\n",
    "  print \"numbers=\", numbers.eval(), numbers.shape\n",
    "  print \"padding=\", padding.eval(), padding.shape\n",
    "  print \"padded=\", padded.eval(), padded.shape\n",
    "  print \"sliced=\", sliced.eval(), sliced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzenie działania modelu na małym zbiorze danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket=dswbiznesie\n",
      "3710 words into gs://dswbiznesie/data/vocab_words\n",
      "{'reviews': <tf.Tensor 'DecodeCSV:0' shape=(?, 1) dtype=string>} Tensor(\"hash_table_Lookup:0\", shape=(?, 1), dtype=int64)\n",
      "Tensor(\"string_to_index_1_Lookup:0\", shape=(?, ?), dtype=int64)\n",
      "words_sliced=SparseTensor(indices=Tensor(\"StringSplit:0\", shape=(?, 2), dtype=int64), values=Tensor(\"StringSplit:1\", shape=(?,), dtype=string), dense_shape=Tensor(\"StringSplit:2\", shape=(2,), dtype=int64))\n",
      "words_embed=Tensor(\"EmbedSequence/embedding_lookup:0\", shape=(?, 77838, 10), dtype=float32)\n",
      "words_conv=Tensor(\"Squeeze_1:0\", shape=(?, 15568), dtype=float32)\n",
      "{'reviews': <tf.Tensor 'DecodeCSV:0' shape=(?, 1) dtype=string>} Tensor(\"hash_table_Lookup:0\", shape=(?, 1), dtype=int64)\n",
      "Tensor(\"string_to_index_1_Lookup:0\", shape=(?, ?), dtype=int64)\n",
      "words_sliced=SparseTensor(indices=Tensor(\"StringSplit:0\", shape=(?, 2), dtype=int64), values=Tensor(\"StringSplit:1\", shape=(?,), dtype=string), dense_shape=Tensor(\"StringSplit:2\", shape=(2,), dtype=int64))\n",
      "words_embed=Tensor(\"EmbedSequence/embedding_lookup:0\", shape=(?, 77838, 10), dtype=float32)\n",
      "words_conv=Tensor(\"Squeeze_1:0\", shape=(?, 15568), dtype=float32)\n",
      "{'reviews': <tf.Tensor 'DecodeCSV:0' shape=(?, 1) dtype=string>} Tensor(\"hash_table_Lookup:0\", shape=(?, 1), dtype=int64)\n",
      "Tensor(\"string_to_index_1_Lookup:0\", shape=(?, ?), dtype=int64)\n",
      "words_sliced=SparseTensor(indices=Tensor(\"StringSplit:0\", shape=(?, 2), dtype=int64), values=Tensor(\"StringSplit:1\", shape=(?,), dtype=string), dense_shape=Tensor(\"StringSplit:2\", shape=(2,), dtype=int64))\n",
      "words_embed=Tensor(\"EmbedSequence/embedding_lookup:0\", shape=(?, 77838, 10), dtype=float32)\n",
      "words_conv=Tensor(\"Squeeze_1:0\", shape=(?, 15568), dtype=float32)\n",
      "Tensor(\"string_to_index_Lookup:0\", shape=(?, ?), dtype=int64)\n",
      "words_sliced=SparseTensor(indices=Tensor(\"StringSplit:0\", shape=(?, 2), dtype=int64), values=Tensor(\"StringSplit:1\", shape=(?,), dtype=string), dense_shape=Tensor(\"StringSplit:2\", shape=(2,), dtype=int64))\n",
      "words_embed=Tensor(\"EmbedSequence/embedding_lookup:0\", shape=(?, 77838, 10), dtype=float32)\n",
      "words_conv=Tensor(\"Squeeze_1:0\", shape=(?, 15568), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://dswbiznesie/data/train.csv...\n",
      "/ [1 files][  3.2 MiB/  3.2 MiB]                                                \n",
      "Operation completed over 1 objects/3.2 MiB.                                      \n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcb08b91790>, '_model_dir': 'outputdir/', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:268: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "2017-11-09 23:58:19.033433: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-11-09 23:58:19.033511: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-11-09 23:58:19.033532: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into outputdir/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.692865, step = 1\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-09-23:58:21\n",
      "INFO:tensorflow:Restoring parameters from outputdir/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-09-23:58:59\n",
      "INFO:tensorflow:Saving dict for global step 1: acc = 0.492754, global_step = 1, loss = 0.7211\n",
      "INFO:tensorflow:Validation (step 1): acc = 0.492754, loss = 0.7211, global_step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.56048\n",
      "INFO:tensorflow:loss = 0.685416, step = 101 (178.419 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into outputdir/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.7113.\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-10-00:03:12\n",
      "INFO:tensorflow:Restoring parameters from outputdir/model.ckpt-200\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-10-00:03:51\n",
      "INFO:tensorflow:Saving dict for global step 200: acc = 0.507246, global_step = 200, loss = 0.690912\n",
      "INFO:tensorflow:Restoring parameters from outputdir/model.ckpt-200\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:Assets written to: outputdir/export/Servo/1510272231/assets\n",
      "INFO:tensorflow:SavedModel written to: outputdir/export/Servo/1510272231/saved_model.pb\n",
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-09 23:58:13.981935. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "echo \"bucket=${BUCKET}\"\n",
    "rm -rf outputdir\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/trainer\n",
    "python -m trainer.task \\\n",
    "   --bucket=${BUCKET} \\\n",
    "   --output_dir=outputdir \\\n",
    "   --job-dir=./tmp --train_steps=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać kod pythonowy działa lokalnie. Można przetestować go lokalnie w Cloud ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.ml-engine.local.train) /usr/bin/python2: command not found\n",
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-10 00:21:54.687180. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "rm -rf trained_model\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${REPO}/notebooks/trainer \\\n",
    "   -- \\\n",
    "   --train_data_paths=${REPO}/notebooks/train.csv \\\n",
    "   --eval_data_paths=${REPO}/notebooks/eval.csv  \\\n",
    "   --num_epochs=10 \\\n",
    "   --output_dir=${REPO}/notebooks/trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('{}/notebooks/outputdir'.format(REPO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print 'Stopped TensorBoard with pid {}'.format(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie można uruchomić do w Cloud ML. Status joba można śledzić w konsoli GCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dswbiznesie/trained_model europe-west1 hygiene_171110_001336\n",
      "jobId: hygiene_171110_001336\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://dswbiznesie/trained_model/__init__.py#1510272792000207...\n",
      "Removing gs://dswbiznesie/trained_model/model.py#1510272792248554...\n",
      "Removing gs://dswbiznesie/trained_model/task.py#1510272792618131...\n",
      "/ [3/3 objects] 100% Done                                                       \n",
      "Operation completed over 3 objects.                                              \n",
      "Copying file://trainer/__init__.py [Content-Type=text/x-python]...\n",
      "Copying file://trainer/model.py [Content-Type=text/x-python]...\n",
      "Copying file://trainer/task.py [Content-Type=text/x-python]...\n",
      "-\n",
      "Operation completed over 3 objects/8.9 KiB.                                      \n",
      "Job [hygiene_171110_001336] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe hygiene_171110_001336\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs hygiene_171110_001336\n",
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-10 00:13:36.438861. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "OUTDIR=gs://${BUCKET}/trained_model\n",
    "JOBNAME=hygiene_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gsutil cp trainer/*.py $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=$(pwd)/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC --runtime-version=1.2 \\\n",
    "   -- \\\n",
    "   --bucket=${BUCKET} \\\n",
    "   --output_dir=${OUTDIR} \\\n",
    "   --train_steps=36000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 29506. Click <a href=\"/_proxy/37208/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "29506"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-10 00:14:07.274171. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped TensorBoard with pid 27841\n",
      "Stopped TensorBoard with pid 29057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-11-10 00:14:00.306155. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Trenowanie modelu w Cloud ML </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Serwowanie predykcji </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
