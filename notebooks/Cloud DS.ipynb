{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Machine Learning w chmurze - Cloud ML </h1>\n",
    "\n",
    "W tym notebooku pokażemy jak przenieść prosty model Tensorflow do GCP i uruchomić na nim predykcje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Predykcje na podstawie tekstu </h2>\n",
    "\n",
    "<b>Źródło danych</b>: Yelp Restaurant Reviews (https://www.yelp.com/dataset/challenge)\n",
    "\n",
    "Dataset zawiera między innymi informacje o restauracjach oraz opinie klientów\n",
    "\n",
    "Zadaniem jest przewidzenie czy restauracje przejdą inspekcje (amerykańskiego) sanepidu na podstawie opinii gości oraz dodatkowych informacji takich jak lokalizacja i rodzaje kuchni serwowanych w restauracji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Ustawienie zmiennych środowiskowych, import bibliotek </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BUCKET = 'dswbiznesie'\n",
    "PROJECT = 'dswbiznesie'\n",
    "REGION = 'europe-west1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%datalab project set -p $PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "import google.datalab.ml as ml\n",
    "import tensorflow as tf\n",
    "import apache_beam as beam\n",
    "import shutil\n",
    "import datetime\n",
    "from apache_beam.io.gcp.internal.clients import bigquery\n",
    "print tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Dane źródłowe </h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset pobrany ze strony Yelp zawiera następujące pliki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 103859986  2017-11-02T23:29:21Z  gs://dswbiznesie/rawdata/hygiene/hygiene.dat\r\n",
      "    762559  2017-11-02T23:29:22Z  gs://dswbiznesie/rawdata/hygiene/hygiene.dat.additional\r\n",
      "     90363  2017-11-02T23:29:23Z  gs://dswbiznesie/rawdata/hygiene/hygiene.dat.labels\r\n",
      "TOTAL: 3 objects, 104712908 bytes (99.86 MiB)\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil -q ls -l gs://$BUCKET/rawdata/hygiene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>hygiene.dat</b>: każda linia zawiera połączone opinie klientów danej restauracji\n",
    "* <b>hygiene.dat.labels</b>: dla pierwszych 546 linii przypisana jest dodatkowe pole w którym 0 oznacza to że restauracja przeszła inspekcje, 1 to że restauracja <b>nie</b> przeszła inspekcji. Reszta wpisów posiada wpis \"[None]\" co oznacza że należą do zbioru testowego\n",
    "* <b>hygiene.dat.additional</b>: plik CSV gdzie w pierwszym polu znajduje się lista oferowanych rodzajów kuchnii, w drugim kod pocztowy restauracji który można uznać za przybliżenie lokalizacji restauracji. W trzecim polu znajduje się liczba opinii, w czwartym średnia ocena ( w skali 0-5, gdzie 5 oznacza ocene najlepszą)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Feature engineering używając Apache Beam i BigQuery</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dane źródłowe należy przetowrzyć i dostosować do postaci której będzie można łatwo użyć do uczenia i ewaluacji modelu. \n",
    "Najwygodniejszym choć nie najtańszym rozwiązaniem jest załadowanie danych do BigQuery.\n",
    "\n",
    "Odpowiednim narzędziem do tego zadania jest Apache Beam i jego implementacja - Google Dataflow.\n",
    "Job Dataflow uruchamiany jest w chmurze. Jego przebieg można śledzić w Konsoli GCP (https://console.cloud.google.com/dataflow).\n",
    "Uruchomienie joba trwa powyżej minuty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#clear BigQuery table here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_record(rest_tuple):\n",
    "    #print(rest_tuple)\n",
    "    identity = rest_tuple[0]\n",
    "    reviews = rest_tuple[1]['reviews_kv'][0]\n",
    "    inspection_result = int(rest_tuple[1]['labels_kv'][0]) if rest_tuple[1]['labels_kv'][0] != \"[None]\" else None\n",
    "    categories_temp = rest_tuple[1]['attributes_kv'][0].split(\"\\\"\")\n",
    "    categories = [ x.replace('\\'', '').replace('[','').replace(']','') for x in categories_temp[1].split(',')]\n",
    "    attributes_temp = categories_temp[2].split(\",\")\n",
    "    zip_code = attributes_temp[1]\n",
    "    review_count = int(attributes_temp[2])\n",
    "    avg_rating = float(attributes_temp[3])\n",
    "    \n",
    "    return { \n",
    "        'identity': identity, \n",
    "        'reviews': reviews,\n",
    "        'inspection_result': inspection_result,\n",
    "        'categories': categories,\n",
    "        'zip_code': zip_code,\n",
    "        'review_count': review_count,\n",
    "        'avg_rating': avg_rating\n",
    "    }\n",
    "\n",
    "def preprocess(RUNNER,BUCKET,BIGQUERY_TABLE):\n",
    "    job_name = 'hygiene-ftng' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    print 'Launching Dataflow job {} ... hang on'.format(job_name)\n",
    "    OUTPUT_DIR = 'gs://{0}/data/hygiene/'.format(BUCKET)\n",
    "    options = {\n",
    "        'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "        'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "        'job_name': 'hygiene-ftng' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S'),\n",
    "        'project': PROJECT,\n",
    "        'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "        'no_save_main_session': True\n",
    "    }\n",
    "    opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "    p = beam.Pipeline(RUNNER, options=opts)\n",
    "    \n",
    "    # Adding table definition\n",
    "    table_schema = bigquery.TableSchema()\n",
    "    \n",
    "    # Fields definition\n",
    "    identity_schema = bigquery.TableFieldSchema()\n",
    "    identity_schema.name = 'identity'\n",
    "    identity_schema.type = 'integer'\n",
    "    identity_schema.mode = 'required'\n",
    "    table_schema.fields.append(identity_schema)\n",
    "    \n",
    "    \n",
    "    reviews_schema = bigquery.TableFieldSchema()\n",
    "    reviews_schema.name = 'reviews'\n",
    "    reviews_schema.type = 'string'\n",
    "    reviews_schema.mode = 'required'\n",
    "    table_schema.fields.append(reviews_schema)\n",
    "\n",
    "    inspection_result_schema = bigquery.TableFieldSchema()\n",
    "    inspection_result_schema.name = 'inspection_result'\n",
    "    inspection_result_schema.type = 'integer'\n",
    "    inspection_result_schema.mode = 'nullable'\n",
    "    table_schema.fields.append(inspection_result_schema)\n",
    "    \n",
    "    categories_schema = bigquery.TableFieldSchema()\n",
    "    categories_schema.name = 'categories'\n",
    "    categories_schema.type = 'string'\n",
    "    categories_schema.mode = 'repeated'\n",
    "    table_schema.fields.append(categories_schema)\n",
    "    \n",
    "    zip_code_schema = bigquery.TableFieldSchema()\n",
    "    zip_code_schema.name = 'zip_code'\n",
    "    zip_code_schema.type = 'string'\n",
    "    zip_code_schema.mode = 'required'\n",
    "    table_schema.fields.append(zip_code_schema)\n",
    "    \n",
    "    review_count_schema = bigquery.TableFieldSchema()\n",
    "    review_count_schema.name = 'review_count'\n",
    "    review_count_schema.type = 'integer'\n",
    "    review_count_schema.mode = 'required'\n",
    "    table_schema.fields.append(review_count_schema)\n",
    "    \n",
    "    avg_rating_schema = bigquery.TableFieldSchema()\n",
    "    avg_rating_schema.name = 'avg_rating'\n",
    "    avg_rating_schema.type = 'float'\n",
    "    avg_rating_schema.mode = 'required'\n",
    "    table_schema.fields.append(avg_rating_schema)\n",
    "    \n",
    "    #processing logic\n",
    "    reviews = p | 'readreviews' >> beam.io.ReadFromText('gs://{0}/rawdata/hygiene/hygiene.dat'.format(BUCKET))\n",
    "    labels = p | 'readlabels' >> beam.io.ReadFromText('gs://{0}/rawdata/hygiene/hygiene.dat.labels'.format(BUCKET))\n",
    "    attributes = p | 'readattributes' >> beam.io.ReadFromText('gs://{0}/rawdata/hygiene/hygiene.dat.additional'.format(BUCKET))\n",
    "    \n",
    "    reviews_kv = reviews | 'mapreviews to kv' >> beam.Map(lambda x: (x.split(\",\")[0], x))\n",
    "    labels_kv = labels | 'maplabels to kv' >> beam.Map(lambda x: (x.split(\",\")[0], x.split(\",\")[1]))\n",
    "    attributes_kv = attributes | 'mapattributes to kv' >> beam.Map(lambda x: (x.split(\",\")[0], x))\n",
    "    \n",
    "    restaurants = (\n",
    "        {'reviews_kv': reviews_kv, 'labels_kv': labels_kv, 'attributes_kv': attributes_kv}\n",
    "        | 'CoGroupByRestaurantKey' >> beam.CoGroupByKey())\n",
    "    \n",
    "    records = restaurants | 'CreateRecords' >> beam.Map(create_record)\n",
    "    \n",
    "    records | 'write' >> beam.io.Write(\n",
    "        beam.io.BigQuerySink(\n",
    "            BIGQUERY_TABLE,\n",
    "            schema=table_schema,\n",
    "            create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "            write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE))\n",
    "    p.run().wait_until_finish()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Uruchomienie etl </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Dataflow job hygiene-ftng-171106-014621 ... hang on\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "bigquery_dataset = PROJECT+\":\"+PROJECT+\".hygiene\"\n",
    "preprocess('DirectRunner',BUCKET, bigquery_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Model Tensorflow </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Trenowanie modelu w Cloud ML </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Serwowanie predykcji </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
